After the installation of QualCoder is completed, the AI-enhanced features require some additional setup. When you start the app for the first time, a **wizard** will appear and guide you through the process. If you choose to skip this wizard, you can restart it later by selecting the menu option "AI > Setup Wizard."

The entire setup process runs mostly automatically and unsupervised. It is a one-time effort that may take some time, so please be patient. The main steps are: 

### 1. Enable the AI

* Note that the AI features are "opt-in" and disabled by default. 
* All AI-related options are located at the bottom of the settings dialog. Scroll down as needed.

Screenshot AI Settings

### 2. Select the AI model you want to use

In QualCoder, you can choose between different AI Large Language Models and even [add your own](#using-other-ai-models). By default, the following services are implemented:

* __GPT-4 by OpenAI: best results, recommended option, albeit not free__ 
    * To use GPT-4, you will need an API key from OpenAI. Visit https://platform.openai.com/, create an account, navigate to your personal dashboard, click on 'API keys' in the left menu, create a key, and paste it into the QualCoder settings dialog. 
    * Although GPT-4 is not free, it is relatively inexpensive. OpenAI charges a small fee for each request, typically just a few cents. You must purchase "credits" from OpenAI before using it; $5 is the minimum amount, which will go a long way.
    * Note that a ChatGPT Plus subscription does not cover usage in QualCoder. You must still purchase credits as described above.
    * QualCoder currently offers the choice between "GPT-4 turbo"—which we still recommend—and "GPT-4o", a newer, cheaper, but slightly less powerful model. Both can use the same API key.

* __Blablador: non-profit, excellent privacy, free to use, medium quality__
    * This service is provided by the German academic research agency [Helmholtz Society](https://www.helmholtz.de/en/). It runs open models, with [Mixtral 8x7b](https://arxiv.org/abs/2401.04088) being the largest currently available, and it is very privacy-friendly, storing no data at all. For more information, see this [presentation from Alexandre Strube](https://strube1.pages.jsc.fz-juelich.de/2024-02-talk-lips-blablador/).
    * A note on quality: Since Blablador utilizes much smaller models than OpenAI, the interpretations are less nuanced. Larger models like GPT-4 provide better context awareness and can even analyze subtle details and implicit meaning to some extent, which is often crucial for qualitative research. Additionally, using Blablador may lead to some glitches in the user interface, such as responses in English instead of the user's language, or malformed source references. For now, we recommend Blablador only for simpler questions, if you wish to experiment with open models, or if you absolutely need the extra privacy (see below for more information on [privacy and data protection](#privacy-and-data-protection)). 
    * Blablador is free to use, but still requires a personal API key from the Helmholtz Society. You can sign up with your university account or with GitHub, Google, or ORCID. Follow the instructions here: [https://sdlaml.pages.jsc.fz-juelich.de/ai/guides/blablador_api_access/](https://sdlaml.pages.jsc.fz-juelich.de/ai/guides/blablador_api_access/).

### 3. Downloading a local AI model

* In addition to the Large Language Models described above, QualCoder also uses a smaller, [local AI model](https://huggingface.co/intfloat/multilingual-e5-large) as a preliminary step in the analysis to limit the amount of data that must be sent to the cloud. 
* This open-source model, approximately 2.5 GB in size, will be automatically downloaded and installed on your computer the first time you activate the AI.

### 4. Reading the empirical documents into the AI memory

* If you have a project open, the aforementioned local AI model will now read through all text documents in the project individually and incorporate them into its internal memory. 
* This process occurs only once. When you reopen the project subsequently, this 'AI memory' will load from the disk quickly. Only if you add new documents to your project or edit existing ones will these documents be read by the local AI (again).
* The entire process of reading and memorizing your documents occurs in the background (status bar showing "AI: reading"). While this is happening, AI-related functions will be unavailable, but you can use the rest of QualCoder as usual.

Once all these steps are completed, the status bar of the app will display "AI: ready," and you can begin using the [AI chat](https://github.com/ccbogel/QualCoder/wiki/5.1.-AI-Chat) or [AI assisted coding](https://github.com/ccbogel/QualCoder/wiki/4.2.-AI-Assisted-Coding) to explore your data.

If you wish to later change the AI model and settings or disable the AI features altogether, you can do so by navigating to "AI > Settings."

## Some Notes on Privacy and Data Protection

* Using cloud-based services like those from OpenAI raises questions regarding data privacy and protection. 
* We believe that QualCoder's use of these services does not violate the ethical principles of qualitative social research. Otherwise, we would not offer such features. 
* However, the final decision rests with you, depending on your specific project and the type of data you handle. We will make it as transparent as possible what happens to your data, enabling you to make an informed decision.  

QualCoder follows a **"Privacy by Design"** approach:  

* The app will **send as little data as possible to the cloud,** utilizing local processing whenever feasible. Most features use the local AI memory described above to make a preselection of relevant data. Subsequently, only a small number of selected text chunks (each about 500 characters long) are sent to the cloud for deeper analysis.  

* With OpenAI, QualCoder utilizes API access to GPT-4, which is governed by the ["Enterprise privacy" regulations](https://openai.com/enterprise-privacy). These regulations are much stricter in terms of data protection compared to ChatGPT. **OpenAI guarantees that the data sent via this interface [will NOT be used to train AI models](https://platform.openai.com/docs/models/how-we-use-your-data#how-we-use-your-data)** but will be kept confidential and deleted within 30 days.

* QualCoder is not limited to using OpenAI. We have partnered with **"Blablador,"** a service running Large Language Models on non-commercial, academic hardware which offers excellent privacy (see above). 

* Additionally, it is possible to [add your own models to QualCoder](#using-other-ai-models), including those running entirely locally on your machine without any network access. As of today, however, the trade-off in output quality is so significant that local AI models have only very limited use cases, in our opinion. This situation will hopefully change in the future.  

* In general, we recommend that you **anonymize your data** very carefully before using any cloud-based AI service for analysis.  

## Using Other AI Models

If you have access to other Large Language Models—on cloud platforms, university servers, or even your own PC—you can try integrating them into QualCoder. This, however, is a highly experimental option and has not been very well tested. We would be interested to hear about your experiences.
* The service you wish to use must provide an interface compatible with the OpenAI API. This is often the case, since this API has become a de facto standard over the past few months. [Ollama](https://ollama.com/blog/openai-compatibility) is a popular example of a server for local LLMs that also offers an OpenAI-compatible API (untested). 
* The available models in QualCoder are defined in the file "config.ini," located in the ".qualcoder" subfolder in the user's home directory. Model definitions have the following format (omit the "<>" marks):
```
[your_model_name]
desc = A description shown in the UI.
       Can have more than one line.
access_info_url = <URL pointing to a website with model info. Can be empty>
large_model = <The exact name of the model in the API>
large_model_context_window = <The maximum number of tokens in a single request>
fast_model = <Can be identical to large_model or name a smaller model, used for simple tasks>
fast_model_context_window = <The maximum number of tokens for the small model>
api_base = <The URL of the API base, e.g., http://localhost:11434/v1 for a local Ollama>
api_key = <The API-key if needed, or "None" instead. Do not leave this field empty.>
```
Again, if you get other services running in QualCoder (or if you tried but failed), we would like to hear about your endeavors.
